{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Special Topics Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Khushi Raghuvanshi\n",
    "- Keshav Tiwari\n",
    "- Maissa Nafisa\n",
    "- Oishani Bandopadhyay\n",
    "- Shivani Kedila"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic and outline\n",
    "\n",
    "### Main topic\n",
    "Explainable AI (XAI) focuses on making machine learning models more interpretable and transparent, especially in high-stakes applications like healthcare, finance, and law. The challenge lies in the complexity of \"black box\" models, which are powerful but difficult for humans to understand. XAI methods like LIME (Local Interpretable Model-Agnostic Explanations) and SHAP (SHapley Additive exPlanations) aim to shed light on these models by providing explanations for their predictions. We will also discuss the pros and cons of XAI techniques in ensuring trust, accountability, and fairness in automated decisions. This presentation will explore the ethical considerations of using black box models, weighing the benefits and risks of knowing or not knowing whatâ€™s inside. \n",
    "\n",
    "### Learning goal for students \n",
    "Students will be able to explain the concept of Explainable AI, compare XAI methods like SHAP and LIME, and evaluate the ethical implications of transparency in machine learning models.\n",
    "\n",
    "\n",
    "### Outline of the topic\n",
    "  - Introduction to Explainable AI (XAI)\n",
    "    - __KEYPOINT__: XAI is crucial for understanding and trusting machine learning models, particularly in critical domains.\n",
    "    - Importance of transparency in black box models\n",
    "    - Is transparency always necessary?\n",
    "\n",
    "  - SHAP vs LIME\n",
    "    - __KEYPOINT__ SHAP is based on game theory and provides both global and local explanations.\n",
    "    - LIME explains models locally by approximating them with simpler, interpretable models.\n",
    "    - Comparision of LIME anf SHAP\n",
    "\n",
    "  - Ethics\n",
    "    - Discussion about Explainable AI vs black box models (more details in active learning section)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedagogy\n",
    "\n",
    "\n",
    "### Readings\n",
    "Readings students will need to consume before class. \n",
    "\n",
    "1. A Perspective on Explainable Artificial Intelligence Methods: SHAP and LIME <a name=\"xaimethods\"></a>[<sup>[1]</sup>](#xaimethods). \n",
    "\n",
    "https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aisy.202400304\n",
    "\n",
    "This reading covers the importance of explainable AI (XAI) methods in making complex machine learning models more transparent and interpretable. It introduces SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-Agnostic Explanations) as two widely used techniques for understanding model predictions. These methods are particularly valuable in high-stakes fields like healthcare, where trust and interpretability are essential for decision-making.\n",
    "\n",
    "The reading compares SHAP and LIME, highlighting their strengths and weaknesses. SHAP provides both local and global explanations using a game-theoretic approach but is computationally intensive. LIME, on the other hand, is faster and easier to implement but only offers local explanations and assumes a linear relationship in feature contributions. Understanding these differences is crucial for selecting the appropriate method based on the specific requirements of a machine learning task.\n",
    "\n",
    "Additionally, the reading discusses challenges associated with XAI, such as model dependency and feature collinearity, which can affect the reliability of explanations. It suggests solutions like using multiple models for comparison and employing additional methods like MIP and shapr to improve interpretability. Students should take away key considerations for effectively using XAI techniques and ensuring that explanations are both accurate and accessible to end-users.\n",
    "\n",
    "### Background literature\n",
    "You will be reading more than the students.  Please put a background section here describing the topics you will cover with citations to the resrouces and primary literature that you read.   \n",
    "\n",
    "**Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "\n",
    "\n",
    "### Lecture description\n",
    "Include some details of what will be covered by traditional lecture.  A slide running order is ideal here, but probably unrealistic.  Include information about how you will apportion coverage between group members.\n",
    "\n",
    "### Active learning\n",
    "Include information about any discussions or exercises you will have students do.  Each active learning exercise needs 1 to 3 short paragraphs.  It should include \n",
    "- the element of the outline this will cover\n",
    "- brief description of framework you will provide to set off the discussion OR a description of the in class exercise\n",
    "- for how long maximum will this run? \n",
    "\n",
    "We will have an interactive section where we split the students into 2 large groups across the class. We will ask them to give us run a simple model on the UCI Loans dataset from the UCI Machine Learning Repository. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates\n",
    "- Week 8: 02/28/2025 \n",
    "- Week 9: 03/07/2025\n",
    "- Week 8: 02/26/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Expectations:\n",
    "* Weekly meetings after class will be scheduled to discuss progress, roadblocks, and next steps.\n",
    "* If anyone is stuck for more than 24 hours, they should reach out for help. \n",
    "* Regular updates will be shared by everyone to the group tp ensure we are always on the same page. \n",
    "* Final submissions will be reviewed at least 24 hours before the deadline to ensure quality and completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/19  |  9 PM | Decide on subtopics  | Each team member will decide on a subtopic and thorougly research on that.| \n",
    "| 2/22  |  8 PM |  Have our sources ready | Look up research papers and decide on readings we will assign each student to before the lecture. | \n",
    "| 2/24  | 3 PM  | Have slides ready for the presentation | Each team member adds their slides to the deck about their subtopic.    |\n",
    "| 2/26  | 2 PM  | Have the interactive model ready | Code our interactive model and make a plan for the lecture. |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"xaimethods\"></a>1.[^](#xaimethods): Salih A. et all (27 June 2024) A Perspective on Explainable Artificial Intelligence Methods: SHAP and LIME*. https://advanced.onlinelibrary.wiley.com/doi/full/10.1002/aisy.202400304<br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11 (default, Jul 27 2021, 07:03:16) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
